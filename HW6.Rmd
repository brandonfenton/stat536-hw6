---
title: "HW 6"
author: "Brandon Fenton and Allison Theobold"
date: "October 18, 2016"
output:
  pdf_document:
    fig_height: 3
    fig_width: 5
  html_document:
    fig_width: 5
  word_document:
    fig_height: 3
    fig_width: 5

header-includes: \usepackage{float} \usepackage{bm} \usepackage{amsmath} \usepackage{amssymb} \usepackage{microtype}
---

```{r setup, include=FALSE, echo=F}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)

library(grid)
library(gridExtra)
library(pander)
library(dplyr)
library(ggplot2)
library(effects)
library(ggfortify)

panderOptions('missing', "-")

pander_lm <-function (fit, ...)
{
  fit.sum <- summary(fit)
  fit.coef <- fit.sum$coefficients
  fit.ttable <- matrix(nrow=length(fit.sum$aliased), ncol=4)
  colnames(fit.ttable) <- colnames(fit.sum$coefficients)
  rownames(fit.ttable) <- names(fit.sum$aliased)

  notna <- as.vector(which(!fit.sum$aliased))
  fit.ttable[notna,] <- fit.coef
  fit.ttable <- as.data.frame(fit.ttable)
  fit.ttable$`Pr(>|t|)` <- ifelse(fit.ttable$`Pr(>|t|)` < 0.0001, "<0.0001",
                                     sprintf("%.4f", fit.ttable$`Pr(>|t|)`))
  

  pander(fit.ttable, ...)
}

pander_anova <-function (fit, ...)
{
  fit.anova <- anova(fit)
  fit.anova$`Pr(>F)` <- ifelse(fit.anova$`Pr(>F)` < 0.0001, "<0.0001",
                                  sprintf("%.4f", fit.anova$`Pr(>F)`))

pander(fit.anova, ...)
}

load("p6.Rdata")
load("p8.Rdata")
```

We will explore one series like those you found in the Vincent and Meki's paper, but for Bozeman.

The following code will count the days in Bozeman where the minimum temperature was measured to be below 32 degrees F (0 degrees C) and the number of days where information was available in `Data1`.

```{r data,warning=F,message=F, echo=F}
Bozeman<-read.csv("Bozeman.csv",header=T)

monthsF<-sort(unique(Bozeman$MonthRE))
countfun<-function(x) c(sum(x<32),sum(!is.na(x)))

  monthcountMINF<-aggregate(Bozeman$TMIN..F., 
                            by=list(Bozeman$MonthRE),FUN=countfun)
  
  yearcountMINF<-aggregate(Bozeman$TMIN..F.,
                           by=list(Bozeman$Year),FUN=countfun)
  
  Data1 <- data.frame(Year = yearcountMINF[,1],
                      DaysBelow32 = yearcountMINF$x[,1],
                      MeasuredDays = yearcountMINF$x[,2],
                      PropDays = yearcountMINF$x[,1]/yearcountMINF$x[,2])
```  

1) Make nice looking and labeled time series plots of the number of days below freezing and the proportion of measured days below freezing.

    ```{r p1, echo=F, fig.width = 10, fig.height = 8}
par(mfrow = c(2, 1))

plot(DaysBelow32 ~ Year, data = Data1, type="l", col = "red", lwd = 2,
     ylab = "Days Below 32 degrees")

plot(PropDays ~ Year, data = Data1, type="l", col = "blue", lwd = 2,
     ylab = "Proportion of Measured Days \nBelow 32 degrees")

```


2) Estimate a linear trend model for the proportion of measured days below freezing and report the parametric (t-test) linear trend test results in a sentence. Also discuss scope of inference for this test in a sentence or two (random sampling and random assignment and their implications).

    ```{r p2, echo=F, warning=FALSE, message=FALSE}
prop_lm <- lm(PropDays ~ Year, data = Data1)
pander_lm(prop_lm)


autoplot(prop_lm, data = Data1, label.size = 3, which = 1:4, ncol = 2)

```

In the model fit, the estimated proportion of measured days below zero decreases between 0.0005 to 0.0001 for every one year increase. There is very strong evidence for a linear relationship between year and proportion of measured days below freezing (t-stat = -3.173 $\sim t_{108},$ p-value = 0.00197). The validity of this test relies on the diagnostics, which we see pictured below. The assumption of constant variance appears severely violated, as the residuals verses fitted values has a sinusoidal trend. The Normal Q-Q plot also raises some concern, as there are substantial deviations as early as the first quantile. 


With these data, the days, months and years were not randomly selected. These data comprise of all sampled days from 1900 to 2008, and therefore our scope of inference only applies to the years (and days, and months) sampled. The temperatures were not randomly assigned to the years (or months or days), hence we can only infer that later years are associated with lower proportions of sampled days below freezing, for these data.  

3) Discuss this proportion response versus using the count of days below zero per year, specific to this example and in general. What issues does using one or the other present? 
    In either case, the model used should be appropriate for the response.  This would mean using either a binomial regression model for proportion responses or a poisson regression model for count responses.  Time series GLMs can be more difficult to implement -- particularly in the case of poisson models -- but if a normal model is fit then other issues arise.  For example, an OLS model could generate predicted proportions falling outside $[0,1]$, or predicted counts with fractional or negative values. 

4) Generate a permutation test for the trend with the proportion response. I performed one in the syllabus (page 6) using the `shuffle` function from the `mosaic` package. Report a plot of the permutation distribution, the _test statistic_ you used, and a p-value. Generally randomization based tests are more robust to violations of the normality assumption as long as the distribution (shape and variability) is the same for all observations except for differences in the _center_ or mean. Why would that be advantageous with this response?

    ```{r p4, echo=F, warning=FALSE, message=FALSE}
# par(mfrow = c(2, 1))
library(mosaic)
library(beanplot)
B <- 1000
Tstar <- matrix(NA, nrow = B)
Tobs <- prop_lm$coefficients[2]
for(i in 1:B){
  Tstar[i] <- lm(PropDays ~ shuffle(Year), data = Data1)$coef[2]
}


qplot(Tstar, geom="histogram",  
      main = expression(paste("Histogram of Permuted ", beta[year])), 
      xlab = "Freq", fill = I("blue"), col = I("black"), 
      alpha=I(.2)) + geom_vline(xintercept = Tobs, colour = "red")

p_value <- pdata(abs(Tstar), abs(Tobs), lower.tail = F)

beanplot(Year ~ PropDays, data = Data1, log = "", col = "bisque", 
         method = "jitter")

```

Above is a plot of 1000 permuted slopes of $\beta_{year},$ with the observed slope plotted in red. In making the permutation distribution of $\beta_{year}$ we assume that there is no linear relationship between the proportion of days sampled that were below freezing and the year. Using the permutation distribution, we find that $\frac{3}{1000}$ permuted slopes are as or more extreme than the observed slope. Due to the violation of Nomality, as seen in the previous diagnostic plots, the permutation test is a safer option, however the test does not alleviate the violation of constant variance. As seen in the above beanplots, the shape of the distribution of proportions varies largely from year to year. 


5) The Sen estimator or, more commonly, Theil-Sen is based on a single median of all the possible pairwise generated slopes. Its standard version is available in the `mblm` (median based linear models) R package developed by Lukasz Komsta. The package description provides more details (https://cran.r-project.org/web/packages/mblm/mblm.pdf). Note that with `mblm`, you need to use `repeated=FALSE` to get the Theil-Sen estimator and not the better estimator developed by Siegel. The package has a `summary` function that provides a test based on the nonparametric Wilcox test but it had terrible Type I error rates when I explored it. Without further explorations, I would recommend avoiding its use. Fortunately, our permutation approach can be used to develop a test based on the Theil-Sen slope coefficient. First, compare the estimated slope provided by `mblm` to what you found from the linear model and its permutation test. Then develop a permutation test based on the slope coefficient from `mblm` - note that `mblm` conveniently has the same output structure as `lm`. The confidence interval that runs on `mblm` seems to perform well enough to study, so we can make 95% confidence intervals and check whether 0 is in the interval or not as the following code suggests to use it to perform our 5% significance level hypothesis test.

In the linear model we obtained an estimated slope of $\beta_{year} = -0.0003117,$ while with `mblm` we obtained an estimate slope of $\beta_{year} = -0.0003161,$ a difference of $4.3776x10^{-6}.$ A 95% confidence interval for $\beta_{year}$ using `mblm` is (-0.0003698, -0.0002405), which does not contain 0. Therefore, similar to the permutation test results, we conclude that $\beta_{year} \neq 0.$   


    ```{r p5,warning=F,message=F, echo=F}
library(mblm)
model1s<-mblm(PropDays~Year,data=Data1,repeated=F)
#summary(model1s)
#confint(model1s)

```

6) Use the residual error variance estimate from your linear model for the proportion responses to simulate a series with no trend (constant mean and you can leave it at 0) and normal white noise with that same variance. Use that simulation code to perform a simulation study of the Type I error rate for the parametric t-test for the slope coefficient, the test using the confidence interval from `mblm`, and your permutation test (use 500 permutations and do 250 simulations to keep the run time somewhat manageable). Report the simulation-based Type I error rates when using a 5% significance level test for the three procedures with the same sample size as the original data set. 

    
    ```{r p6fns, echo = F, cache = TRUE}

t_function <- function(x){
  p_value <- summary(lm(x ~ Data1$Year))$coef[2, 4]
  decision <- ifelse(p_value < 0.05, 1, 0)
  return(decision)
}

mblm_function <- function(x){
  z <- data.frame(Year = Data1$Year, x)
  model <- mblm(x ~ Year, z, repeated = F)
  CI <- confint(model)
  decision <- ifelse(CI[1] <= 0 & CI[2] >= 0, 0, 1)
  return(decision)
}

permute_function <- function(x){
  B <- 5000
  Tstar <- matrix(NA, nrow = B)
  Tobs <- prop_lm$coefficients[2]
    for(i in 1:B){
        Tstar[i] <- lm(x ~ shuffle(Data1$Year))$coef[2]
    } 
  p_value <- pdata(abs(Tstar), 0, lower.tail = F)
  decision <- ifelse(p_value < 0.05, 1, 0)
  return(decision)
}

sigma.est <- summary(prop_lm)$sigma


```

    ```{r p6, echo = F, cache = TRUE, eval=F}
# Results are loaded in the setup chunk
sim_data <- replicate(250, replicate(109, rnorm(1, 0, sigma.est)))




t_type_1 <- apply(sim_data, 2, t_function)

# sum(t_type_1) = 6/250 = 0.024 Type 1 error rate



mblm_type_1 <- apply(sim_data, 2, mblm_function)

# sum(mblm_type_1) = 



permute_type_1 <- apply(sim_data, 2, permute_function)

#sum(permute_type_1) = Type 1 error rate  
save(sim_data, t_type_1, mblm_type_1, permute_type_1, file="p6.Rdata")
```

```{r p6a, echo=F}

uncor.tI <- data.frame(rbind(mean(t_type_1), mean(mblm_type_1), mean(permute_type_1)))

rownames(uncor.tI) <- c("t-test", "mblm", "permutation")
colnames(uncor.tI) <- "Type I Error"

uncor.tI[,1] <- ifelse(uncor.tI[,1] < 0.001, "<0.001",
                                     sprintf("%.3f", uncor.tI[,1]))
pander(uncor.tI)
```
7) Instead of white noise errors, we might also be interested in Type I error rates when we have autocorrelation present (again with no trend in the true process). Use the results for an AR(1) process variance (derived in class) to calculate the white noise variance needed to generate a process with the same variance as you used for your previous simulation, but when $\phi = 0.3$ and 0.6. In other words, $\gamma_0$ of the AR(1) process needs to match the white noise variance used above and the white noise process driving the AR(1) process needs to be adjusted appropriately. 

  - Show your derivation of the required white noise variances first for $\phi = 0.3$ and $\phi = 0.6$.   
  
    ```{r p7, echo = T}
ar1.03.error <- (1 - 0.3^2)*sigma.est
ar1.06.error <- (1 - 0.6^2)*sigma.est 

ar1.03.error
ar1.06.error
```
  
  
  - To simulate the process we can use this value in the `arima.sim` function in something like `arima.sim(n=2000,list(ar=c(0.3)),sd=5)` where `n=2000` provides 2000 simulated observations, `model=list(ar=c(0.3))` determines that we are using an AR(1) process with parameter of of 0.3, and `sd=5` controls the SD of the normal white noise used to build the AR(1) process (this is _not_ the variance of the AR(1) process). Check that you get about your expected results using something like:
  
    ```{r p7a, warning=F,message=F}
ar1sim <- arima.sim(n = 2000, model = list(ar = c(0.6)), 
                    sd = sqrt(ar1.06.error))
var(ar1sim)
sigma.est

```

8) Repeat your simulation study of the parametric, permutation, and Theil-Sen linear trend test based on the CI. Report the estimated Type I error rates in the presence of AR(1) correlations with a parameter of 0.6 based on your work in the previous question for simulating the response time series. Discuss the impacts of having autocorrelation present on the various procedures.

    ```{r p8, echo=F, cache=TRUE, eval=F}
# Results are loaded in the setup chunk
ar_sim_data <- replicate(250, arima.sim(n = 109, model = list( ar = c(0.6)),
                                        sd = sqrt(ar1.06.error)))


t_ar_type_1 <- apply(ar_sim_data, 2, t_function)
#sum(t_ar_type_1) = 74/250 = 0.296 Type 1 error rate

mblm_ar_type_1 <- apply(ar_sim_data, 2, mblm_function)
# sum(mblm_ar_type_1) = 

permute_ar_type_1 <- apply(ar_sim_data, 2, permute_function)
# sum(permute_ar_type_1) = Type 1 error rate  
save(ar_sim_data, t_ar_type_1, mblm_ar_type_1, permute_ar_type_1, file="p8.Rdata")
```

9) The Zhang method you read about is also available in the `zyp` package but it only provides confidence intervals and I am not completely convinced by their discussion of the intervals provided without more exploration. But you can get estimates from `zyp.sen` and confidence intervals using `confint.zyp` on the results from `zyp.sen`. The `confint` function can also be applied to `mblm` results. Find and compare the two confidence intervals for the Sen-estimators for the proportion response time series. No simulation study here - just complete the analysis.  

    ```{r p9, echo=F, message=F}
library(mblm)
library(zyp)
model_zyp <- zyp.sen(PropDays ~ Year,data = Data1)
zyp <- confint.zyp(model_zyp)
mblm <- confint(model1s)

CIs <- cbind(zyp[2,], mblm[2,])
row.names(CIs) <- c("zyp", "mblm")
colnames(CIs) <- c("0.025", "0.975")

pander(CIs)
```


10) Make a plot of the original proportion response time series with the parametric linear, Theil-Sen, and Zhang methods/models on the same plot. You may want to use `plot(y~x,type="l")` and then add lines to the plot.

    ```{r p10, echo=F}
par(mfrow = c(1, 1))
plot(PropDays ~ Year, data = Data1, type="l", col = "blue", lwd = 2,
     ylab = "Proportion of Measured Days \nBelow 32 degrees")

curve(prop_lm$coef[1] + prop_lm$coef[2]*x, type = "l", 
      col = "red", add = T, lty = 2, lwd = 2)

curve(model1s$coef[1] + model1s$coef[2]*x, type = "l", add = T,
      col = "green", lty = 3, lwd = 2)

curve(model_zyp$coef[1] + model_zyp$coef[2]*x, type = "l", add = T, lwd = 2, 
      col = "black", lty = 4)

legend("topright", legend = c("lm", "mblm", "zyp"), 
       col = c("red", "green", "black"), lwd = c(2, 2, 2), lty = c(2, 3, 4))
```

## R code appendix

# Setup
```{r a0, ref.label="setup", eval=F}

```

```{r a0a, ref.label="data", eval=F}

```

# Problem 1
```{r a1, ref.label="p1", eval=F}

```

# Problem 2
```{r a2, ref.label="p2", eval=F}

```

# Problem 4
```{r a4, ref.label="p4", eval=F}

```

# Problem 5
```{r a5, ref.label="p5", eval=F}

```

# Problem 6

```{r a6fns, ref.label="p6fns", eval=F}

```

```{r a6, ref.label="p6", eval=F}

```

# Problem 7
```{r a7, ref.label="p7", eval=F}

```

```{r a7a, ref.label="p7a", eval=F}

```

# Problem 8
```{r a8, ref.label="p8", eval=F}

```

# Problem 9
```{r a9, ref.label="p9", eval=F}

```

# Problem 10
```{r a10, ref.label="p10", eval=F}

```